DÃ©veloppement d'un Chat Bot de GÃ©nÃ©ration de Courriers ou de Mails 

Objectif 

DÃ©velopper une application web utilisant une Intelligence Artificielle gÃ©nÃ©rative hÃ©bergÃ©e en local, capable de gÃ©nÃ©rer des mails et des courriers en fonction de contextes particuliers et de modÃ¨les. 

ğŸ”¹ Une application web complÃ¨te a Ã©tÃ© dÃ©veloppÃ©e : interface utilisateur, backend Flask. 

Moteur IA 

Installation d'un moteur IA en local sur une machine virtuelle (Environnement Proxmox) 

ğŸ”¹ Moteur IA local (Ollama : mannix/hermes-3-llama-3.1-8b) pour gÃ©nÃ©rer des emails. 

 ğŸ”¹ Mais actuellement j'utilise qwen2.5:0.5b pour des tests plus rapides en dÃ©pit de la qualitÃ© de gÃ©nÃ©ration. 

Base de DonnÃ©es 

CrÃ©ation d'une base de donnÃ©es (Prompts, logs) 

ğŸ”¹ Base de donnÃ©es SQLite implÃ©mentÃ©e avec SQLAlchemy : 

Table User : gestion des comptes administrateurs (username, password, role) 

Table ChatLog : historique des conversations (user_id, sender, message, timestamp) 

ğŸ”¹ Stockage des prompts dans prompts.json 

 

API Backend 

DÃ©veloppement d'une API en Python pour la gestion du moteur IA (ParamÃ©trage, Prompts/RÃ©ponses, Gestion des erreurs, Logs) 

ğŸ”¹ Le backend de l'application repose sur deux Ã©lÃ©ments principaux situÃ©s dans : 

 jarvis@Jarvis:/opt/chatbot-docker/backend/ 

Le dossier logic reprÃ©sente l'API backend. Il contient la logique liÃ©e au moteur d'intelligence artificielle : 

Le paramÃ©trage 

La gestion des prompts et des rÃ©ponses 

La gestion des erreurs 

Et le fichier app.py : 

Ce fichier contient la logique Flask. Il permet : 

D'afficher les pages HTML via diffÃ©rentes routes, la page principale Ã©tant index.html 

De dÃ©finir des routes supplÃ©mentaires accessibles via URL (ex. : /start) qui permettent au JavaScript d'interagir dynamiquement avec logic.py. Ces routes ne retournent pas de page HTML directement mais permettent de charger des contenus au dÃ©marrage ou en action utilisateur. 

ğŸ”¹ L'API communique avec le moteur Ollama via des appels HTTP (API REST). 

 La fonction ollama_chat envoie les prompts et rÃ©cupÃ¨re les rÃ©ponses du modÃ¨le local. 

Frontend 

DÃ©veloppement d'une interface utilisateur pour l'exploitation du chatbot (SÃ©lection du type de document, formulaire contextuel, gÃ©nÃ©ration du texte, copie de la rÃ©ponse) 

ğŸ”¹ HTML/CSS assurent l'affichage de l'interface. 

 JavaScript gÃ¨re les interactions dynamiques avec le backend, comme l'affichage des messages, la gÃ©nÃ©ration des formulaires et l'envoi des requÃªtes vers l'API Flask. 

Frontend Admin 

DÃ©veloppement d'une interface utilisateur pour la gestion des prompts (formulaires) et consultation des logs 

ğŸ”¹ Interface d'administration implÃ©mentÃ©e avec : 

Gestion des utilisateurs (admin/superadmin) 

Authentification sÃ©curisÃ©e 

Interface de gestion des prompts 

Visualisation des logs de conversation 

Structure 

Serveur Ubuntu : 

XXX.XXX.XXX.XXX

ğŸ”¹ Tous les services sont hÃ©bergÃ©s sur ce serveur via Docker : 

backend Flask 

frontend statique 

serveur Nginx 

moteur IA Ollama 

Moteur IA 

ğŸ”¹ DÃ©ployÃ© dans un conteneur Docker via l'image ollama/ollama, modÃ¨le utilisÃ© : qwen2.5:0.5b. 

API Backend 

ğŸ”¹ Backend Python (Flask + Gunicorn), contenu dans un conteneur chatbot-backend. 

 Expose des routes pour l'interface et la gÃ©nÃ©ration. 

Base de DonnÃ©es 

ğŸ”¹ SQLite avec SQLAlchemy, stockÃ©e localement dans le conteneur backend 

Portainer 

Frontend 

ğŸ”¹ Fichiers HTML, CSS et JS statiques servis par Nginx depuis nginx/www. 

 Interface utilisateur principale. 

Ã‰volutions Possibles 

Connexion SSO (AD) Ã  l'interface web 

Historique de gÃ©nÃ©ration consultable 

GÃ©nÃ©ration de documents (.doc, .xls) selon des modÃ¨les 

AmÃ©lioration de la sÃ©curitÃ© (hachage des mots de passe) 

 

 
